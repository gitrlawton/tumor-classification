from threading import Thread
import os
import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
import cv2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
import google.generativeai as genai
import PIL.Image
from dotenv import load_dotenv
load_dotenv()

#ngrok_token = os.getenv("NGROK_AUTH_TOKEN")

# Set up genai library.
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in environment variables")

genai.configure(api_key=api_key)


# Create a directory for our saliency maps if one does not already exist.
output_dir = "saliency_maps"
os.makedirs(output_dir, exist_ok=True)

# Helper function to run streamlit.
def run_streamlit():
    os.system("streamlit run /main.py --server.port 8501")
 
# Function to generate an explanation of the model's prediction.   
def generate_explanation(img_path, model_prediction, confidence):
    prompt = f"""You are an expert neurologist. You are tasked with explaining a 
    saliency map of a brain tumor MRI scan. The saliency map was generated by a deep 
    learning model that was trained to classify brain tumors as either glioma, 
    meningioma, pituitary, or no tumor.

    The saliency map highlights the regions of the image that the machine learning 
    model is focusing on to make the prediction.  The deep learning model predicted 
    the image to be of class '{model_prediction}' with a confidence of 
    {confidence * 100}%.

    In your response:
    - Explain what regions of the brain the model is focusing on, based on the 
    saliency map. Refer to the regions 
    highlighted in light cyan, those are the regions the model is focusing on.  
    - Explain possible reasons why the model made the prediction it did.
    - Don't mention anything like "The saliency map highlights the regions the model 
    is focusing on, which are in light cyan" in your explanation.
    - Keep your explanation to 4 sentences max.
    
    Let's think step by step about this.  Verify step by step.
    """

    img = PIL.Image.open(img_path)
    model = genai.GenerativeModel(model_name="gemini-1.5-flash")
    response = model.generate_content([prompt, img])
    
    return response.text

# Function to generate saliency map.
def generate_saliency_map(model, img_array, class_index, img_size):
    with tf.GradientTape() as tape:
        # Tensor format of the image that TensorFlow can work with.
        img_tensor = tf.convert_to_tensor(img_array)
        tape.watch(img_tensor)
        # Make a prediction on the image.
        predictions = model(img_tensor)
        target_class = predictions[:, class_index]
    
    # Calculating the gradients, which tell us which parts of the image have
    # the biggest impact on the prediction (what pixels were the most important.)
    gradients = tape.gradient(target_class, img_tensor)
    # Take the absolute value to determine the magnitude.
    gradients = tf.math.abs(gradients)
    gradients = tf.reduce_max(gradients, axis = -1)
    # Convert from a tensor back to an array.
    gradients = gradients.numpy().squeeze()
    
    # Resize gradients to match original image size
    gradients = cv2.resize(gradients, img_size)
    
    # Create a circular mask for the brain area
    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
    radius = min(center[0], center[1]) - 10
    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
    
    # Apply mask to gradients
    gradients = gradients * mask
    
    # Normalize only the brain area
    brain_gradients = gradients[mask]
    if brain_gradients.max() > brain_gradients.min():
        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
    gradients[mask] = brain_gradients
    
    # Apply a higher threshold
    threshold = np.percentile(gradients[mask], 80)
    gradients[gradients < threshold] = 0
    
    # Apply more aggressive smoothing
    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)
    
    # Create a heatmap overlay with enhanced contrast
    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    
    # Resize heatmap to match original image size
    heatmap = cv2.resize(heatmap, img_size)

    # Superimpose the heatmap on original image with increased opacity
    original_img = image.img_to_array(img)
    superimposed_img = heatmap * 0.7 + original_img * 0.3
    superimposed_img = superimposed_img.astype(np.uint8)

    img_path = os.path.join(output_dir, uploaded_file.name)
    with open(img_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    saliency_map_path = f"saliency_maps/{uploaded_file.name}"

    # Save the saliency map
    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

    return superimposed_img
    
# Function to load our Xception model.
def load_xception_model(model_path):
    img_shape=(299, 299, 3)
    base_model = tf.keras.applications.Xception(include_top=False, 
                                                weights="imagenet",
                                                input_shape=img_shape, 
                                                pooling="max")
    
    model = Sequential([
        base_model,
        Flatten(),
        Dropout(rate=0.3),
        Dense(128, activation='relu'),
        Dropout(rate=0.25),
        Dense(4, activation='softmax')
    ])
    
    model.build((None,) + img_shape)
    
    # Compile the model
    model.compile(Adamax(learning_rate=0.001),
                 loss='categorical_crossentropy',
                 metrics=['accuracy',
                         Precision(),
                         Recall()])
    
    model.load_weights(model_path)
    
    return model

# Create a new thread to run the streamlit app in the background.
#thread = Thread(target=run_streamlit)
#thread.start()

# Create a public url for the app.
#public_url = ngrok.connect(addr='8501', proto='http', bind_tls=True)

#print("Public URL:", public_url)

# Title of the web app.
st.title("Brain Tumor Classification")

st.write("Upload an image of a brain MRI scan to classify.")

# Create upload file widget.
uploaded_file = st.file_uploader("Choose an image", type=["jpg", "jpeg", "png"])

# If the user uploaded a file...
if uploaded_file is not None:
    # Allow user to select a model
    selected_model = st.radio("Select Model", ("Transfer Learning - Xception", "Custom CNN"))
    
    # Load that model in
    if selected_model == "Transfer Learning - Xception":
        model = load_xception_model("models/xception_model.weights.h5")
        img_size = (299, 299)
    else:
        model = load_model("models/cnn_model.h5")
        img_size = (224, 224)
        
    # Define the different classes
    labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']
    # Load in the image and set to the target size
    img = image.load_img(uploaded_file, target_size=img_size)
    # Convert the image to an array
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    # Normalize the array so the pixel values are between 0 and 1 because that is
    # how the model was trained.
    img_array /= 255.0

    # Make a prediction with the model
    prediction = model.predict(img_array)

    # Get the class with highest probability...
    class_index = np.argmax(prediction[0])
    # ...and store it in the result.
    result = labels[class_index]

    # Display the highest probability...
    st.write(f"Predicted Class: {result}")
    # ...along with all the other probabilities.
    st.write("Probabilities:")
    for label, prob in zip(labels, prediction[0]):
        st.write(f"{label}: {prob:.4f}")
        
    # Generate the saliency map
    saliency_map = generate_saliency_map(model, img_array, class_index, img_size)
    col1, col2 = st.columns(2)
    # Create two columns, one to display the original image, and another for the
    # saliency map.
    with col1:
        st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)
    with col2:
        st.image(saliency_map, caption='Saliency Map', use_column_width=True)
    
    ##---- GENERATE AND DISPLAY CLASSIFICATION RESULTS ----##
    
    st.write("## Classification Results")
    
    result_container = st.container()
    result_container = st.container()
    result_container.markdown(
        f"""
        <div style="background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px;">
            <div style="display: flex; justify-content: space-between; align-items: center;">
                <div style="flex: 1; text-align: center;">
                    <h3 style="color: #ffffff; margin-bottom: 10px; font-size: 20px;">Prediction</h3>
                    <p style="font-size: 36px; font-weight: 800; color: #FF0000; margin: 0;">
                        {result}
                    </p>
                </div>
                <div style="width: 2px; height: 80px; background-color: #ffffff; margin: 0 20px;"></div>
                <div style="flex: 1; text-align: center;">
                    <h3 style="color: #ffffff; margin-bottom: 10px; font-size: 20px;">Confidence</h3>
                    <p style="font-size: 36px; font-weight: 800; color: #2196F3; margin: 0;">
                        {prediction[0][class_index]:.4%}
                    </p>
                </div>
            </div>
        </div>
        """,
        unsafe_allow_html=True
    )
    
    # Prepare data for Plotly chart
    probabilities = prediction[0]
    sorted_indices = np.argsort(probabilities)[::-1]
    sorted_labels = [labels[i] for i in sorted_indices]
    sorted_probabilities = probabilities[sorted_indices]

    # Create a Plotly bar chart
    fig = go.Figure(go.Bar(
        x=sorted_probabilities,
        y=sorted_labels,
        orientation='h',
        marker_color=['red' if label == result else 'blue' for label in sorted_labels]
    ))
    
    # Customize the chart layout
    fig.update_layout(
        title = 'Probabilities for each class',
        xaxis_title = 'Probability',
        yaxis_title = 'Class',
        height = 400,
        width = 600,
        yaxis = dict(autorange="reversed")
    )

    # Add value labels to the bars
    for i, prob in enumerate(sorted_probabilities):
        fig.add_annotation(
            x = prob,
            y = i,
            text = f"{prob:.4f}",
            showarrow = False,
            xanchor = 'left',
            xshift = 5
        )

    # Display the Plotly chart
    st.plotly_chart(fig)
    
    ##---- GENERATE AND DISPLAY EXPLANATION ----##
        
    # Get the path of the saliency map.
    saliency_map_path = f"saliency_maps/{uploaded_file.name}"
    explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])
    
    # Write the explanation to the screen.
    st.write("## Explanation")
    st.write(explanation)